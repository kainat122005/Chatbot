# -*- coding: utf-8 -*-
"""Docx2txt--CSV

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LLHYoHtg9yx0eCMZNphMOklY5lsvOYT5
"""

pip install langchain streamlit pyngrok google_generativeai langchain_google_genai --quiet

"""# **Ingestion**"""

pip install langchain_community --quiet

pip install CSVLoader --quiet

"""CSV-----For Q/A in excel,Notepads"""

from google.colab import files
from langchain.document_loaders import CSVLoader

uploaded=files.upload()

document_loaders=list(uploaded.keys())[0]
loaders=CSVLoader("/content/"+document_loaders)
docs=loaders.load()

"""Docs2txt-----Word file"""

pip install Docx2txt --quiet

from langchain_community import document_loaders

from google.colab import files
from langchain.document_loaders import Docx2txtLoader
from langchain.document_loaders import CSVLoader

uploaded=files.upload()

document_loaders=list(uploaded.keys())[0]
loaders=Docx2txtLoader("/content/"+document_loaders)
docs=loaders.load()

#split
from langchain.text_splitter import RecursiveCharacterTextSplitter
text_splitter= RecursiveCharacterTextSplitter(
    chunk_size=100,
    chunk_overlap=100
)
chunks=text_splitter.split_documents(docs)

#Embedding
from langchain_google_genai import GoogleGenerativeAIEmbeddings
embeddings=GoogleGenerativeAIEmbeddings(model="models/embedding-001",google_api_key="AIzaSyAaI6cEtck9zu9Vb0UphPTez2BkFRzFXdw")

# Import QdrantVectorStore first
from langchain_community.vectorstores import Qdrant as QdrantVectorStore

!pip install qdrant-client --quiet

qdrant_url = "https://fe58f34e-8a11-44b7-bc37-b36c7b67f516.us-west-1-0.aws.cloud.qdrant.io:6333"
qdrant_api_key = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.ZOuPanOWtPTZX6-ixCgGJ-SytMMUBco320lUIenAOgk"
collection_name="hope_cluster"

#Initialize qdrant vector store and embediing the model
qdrant=QdrantVectorStore.from_documents(
    docs,
    embeddings,
    url=qdrant_url,
    api_key=qdrant_api_key,
    collection_name=collection_name
)

"""# **Retrieval**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile chat.py
# import streamlit as st
# st.title("Chatbot")
# st.subheader("Ask any question from uploaded book or documents.")
# query=st.text_input("Ask any question")
# if query:
#   from langchain_community.vectorstores import Qdrant as QdrantVectorStore
#   from langchain_google_genai import GoogleGenerativeAIEmbeddings,ChatGoogleGenerativeAI
#   embeddings=GoogleGenerativeAIEmbeddings(
#       model="models/embedding-001",google_api_key="AIzaSyAaI6cEtck9zu9Vb0UphPTez2BkFRzFXdw"
#   )
#   qdrant=QdrantVectorStore.from_documents(
#     docs,
#     embeddings,
#     url=qdrant_url,
#     api_key=qdrant_api_key,
#     collection_name=collection_name
#   )
#   llm=ChatGoogleGenerativeAI(
#               model="gemini-1.5-flash",
#         google_api_key="AIzaSyAaI6cEtck9zu9Vb0UphPTez2BkFRzFXdw"
#   )
#   from langchain.chains import RetrievalQA
#   retrieval = qdrant.as_retriever()
#   qa_chain=RetrievalQA.from_chain_type(llm=llm,retrieval=retrieval)
#   result=qa_chain.run(query)
#   st.write(result)
#

from pyngrok import ngrok
from pyngrok import conf, ngrok

conf.get_default().auth_token = "2zfunESQOXuU1fVAm7qWOen54Rw_88ysqJqm4T7Vogtmn1eLN"
!streamlit run chatbot.py &> /content/logs.txt &
public_url = ngrok.connect(8501)
print(" Your chatbot is live at:", public_url)