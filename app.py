# -*- coding: utf-8 -*-
import streamlit as st

"""Docx2txt--NP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LLHYoHtg9yx0eCMZNphMOklY5lsvOYT5

# **Ingestion**

Docs2txt-----Word file
"""

from langchain_community import document_loaders


from langchain.document_loaders import Docx2txtLoader

import streamlit as st

st.title("Docs2txt-----Word file")
st.subheader("Upload a document")

# Upload the file
uploaded_file = st.file_uploader("Upload a document", type=["txt", "pdf", "csv", "docx"])

# Check if a file was uploaded
if uploaded_file is not None:
    document_loaders = uploaded_file.name
    st.success("File uploaded successfully!")
    st.write("Filename:", document_loaders)
else:
    st.warning("Please upload a file to continue.")



    document_loaders = uploaded_file.name

    loaders=CSVLoader("/content/"+document_loaders)
    docs=loaders.load()

#split
from langchain.text_splitter import RecursiveCharacterTextSplitter
text_splitter= RecursiveCharacterTextSplitter(
    chunk_size=100,
    chunk_overlap=100
)
chunks=text_splitter.split_documents(docs)

#Embedding
from langchain_google_genai import GoogleGenerativeAIEmbeddings
embeddings=GoogleGenerativeAIEmbeddings(model="models/embedding-001",google_api_key="AIzaSyAaI6cEtck9zu9Vb0UphPTez2BkFRzFXdw")

# Import QdrantVectorStore first
from langchain_community.vectorstores import Qdrant as QdrantVectorStore

qdrant_url = "https://fe58f34e-8a11-44b7-bc37-b36c7b67f516.us-west-1-0.aws.cloud.qdrant.io:6333"
qdrant_api_key = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.ZOuPanOWtPTZX6-ixCgGJ-SytMMUBco320lUIenAOgk"
collection_name="hope_cluster"

#Initialize qdrant vector store and embediing the model
qdrant=QdrantVectorStore.from_documents(
    docs,
    embeddings,
    url=qdrant_url,
    api_key=qdrant_api_key,
    collection_name=collection_name
)

"""# **Retrieval**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile chatbot.py
# import streamlit as st
# st.title("Chatbot")
# st.subheader("Ask any question from uploaded book or documents.")
# query=st.text_input("Ask any question")
# if query:
#   from langchain_community.vectorstores import Qdrant as QdrantVectorStore
#   from langchain_google_genai import GoogleGenerativeAIEmbeddings,ChatGoogleGenerativeAI
#   embeddings=GoogleGenerativeAIEmbeddings(
#       model="models/embedding-001",google_api_key="AIzaSyAaI6cEtck9zu9Vb0UphPTez2BkFRzFXdw"
#   )
#   qdrant=QdrantVectorStore.from_documents(
#     docs,
#     embeddings,
#     url=qdrant_url,
#     api_key=qdrant_api_key,
#     collection_name=collection_name
#   )
#   llm=ChatGoogleGenerativeAI(
#               model="gemini-1.5-flash",
#         google_api_key="AIzaSyAaI6cEtck9zu9Vb0UphPTez2BkFRzFXdw"
#   )
#   from langchain.chains import RetrievalQA
#   retrieval = qdrant.as_retriever()
#   qa_chain=RetrievalQA.from_chain_type(llm=llm,retrieval=retrieval)
#   result=qa_chain.run(query)
#   st.write(result)
#
